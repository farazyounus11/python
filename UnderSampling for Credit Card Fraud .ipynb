{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "96c780c7-fe71-43e4-91cd-814488fb06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "# Load the dataset\n",
    "\n",
    "data = pd.read_csv(\"credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fddc4cdf-b108-45de-b818-85332a035d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b7b8758-2308-43db-a04e-41820b81dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import andrews_curves\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Assuming 'data' is your DataFrame containing the features and target\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa29c55f-9458-40ea-b669-aba0c1d0f6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[56832    20]\n",
      " [   42    68]]\n",
      "False Positives: 20\n",
      "False Negatives: 42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "logreg = LogisticRegression(random_state=42, max_iter=4000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a541926-4dad-4cef-8a3b-84b5fe4a7e09",
   "metadata": {},
   "source": [
    "## You can see above that there are 45 false negatives. 45 people got away. I will reduced this significantly by using statistical techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587b10e-d080-496e-8180-4f1b3503147d",
   "metadata": {},
   "source": [
    "## First I will use under sampling becaus the dataset is really unbalanced. You can see the unbalance below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a2f6205-ab06-4d88-bcc3-5cadbceb2f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_counts = y.value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "label_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b0139f55-d969-4dd4-820d-3f458decf096",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below I am using randoundersampler to fix the label balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "be37ddb6-48ed-4e27-b31c-1d72b459828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# First, split your dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42 )\n",
    "\n",
    "# Initialize RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b35b66-a93c-4735-9b1a-524fad620bf5",
   "metadata": {},
   "source": [
    "## Below you see that I did 50:50 sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd6248c4-b197-4a78-97ba-c472825f2a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of labels in the resampled training set:\n",
      "Class\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "resampled_label_counts = y_train_res.value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Percentage of labels in the resampled training set:\")\n",
    "print(resampled_label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a49d50f-06c6-44a2-8cc6-72c55a8fbd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(788, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(788,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "y_train_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49565e24-9860-4a5b-beaa-dc7b99f93dd8",
   "metadata": {},
   "source": [
    "## After undersampling. I will apply regularization. I will do gridsearch to find best regularizaiton parameter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "20819d40-6a5f-4f48-a44f-1a14ca99d51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: l1, C: 0.01\n",
      "False Positives: 136\n",
      "False Negatives: 19\n",
      "---------------------------------------------------\n",
      "Penalty: l1, C: 0.1\n",
      "False Positives: 819\n",
      "False Negatives: 12\n",
      "---------------------------------------------------\n",
      "Penalty: l1, C: 0.5\n",
      "False Positives: 1525\n",
      "False Negatives: 8\n",
      "---------------------------------------------------\n",
      "Penalty: l1, C: 1\n",
      "False Positives: 1711\n",
      "False Negatives: 8\n",
      "---------------------------------------------------\n",
      "Penalty: l1, C: 2\n",
      "False Positives: 1943\n",
      "False Negatives: 8\n",
      "---------------------------------------------------\n",
      "Penalty: l2, C: 0.01\n",
      "False Positives: 284\n",
      "False Negatives: 17\n",
      "---------------------------------------------------\n",
      "Penalty: l2, C: 0.1\n",
      "False Positives: 989\n",
      "False Negatives: 10\n",
      "---------------------------------------------------\n",
      "Penalty: l2, C: 0.5\n",
      "False Positives: 1416\n",
      "False Negatives: 8\n",
      "---------------------------------------------------\n",
      "Penalty: l2, C: 1\n",
      "False Positives: 1632\n",
      "False Negatives: 8\n",
      "---------------------------------------------------\n",
      "Penalty: l2, C: 2\n",
      "False Positives: 1835\n",
      "False Negatives: 8\n",
      "---------------------------------------------------\n",
      "Best configuration with minimum false negatives: Penalty=l1, C=0.5\n",
      "Confusion Matrix of the best configuration:\n",
      "1525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "regularization_strengths = [0.01, 0.1,.5, 1,2]\n",
    "penalties = ['l1', 'l2']\n",
    "\n",
    "results = []\n",
    "\n",
    "for penalty in penalties:\n",
    "    for C in regularization_strengths:\n",
    "        solver = 'liblinear' if penalty == 'l1' else 'lbfgs'\n",
    "        logreg = LogisticRegression(C=C, penalty=penalty, solver=solver, random_state=42, max_iter=10000)\n",
    "        logreg.fit(X_train_scaled, y_train_res)\n",
    "        y_pred = logreg.predict(X_test_scaled)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        # Store only false positives and false negatives\n",
    "        results.append((penalty, C, fp, fn))\n",
    "        \n",
    "        print(f\"Penalty: {penalty}, C: {C}\")\n",
    "        print(f\"False Positives: {fp}\")\n",
    "        print(f\"False Negatives: {fn}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n",
    "\n",
    "min_fn_result = min(results, key=lambda x: x[3])\n",
    "print(f\"Best configuration with minimum false negatives: Penalty={min_fn_result[0]}, C={min_fn_result[1]}\")\n",
    "print(\"Confusion Matrix of the best configuration:\")\n",
    "print(min_fn_result[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9e2fb-2a10-4bc8-ab1b-35ee7dbd38eb",
   "metadata": {},
   "source": [
    "## Below, I will show how catboost reduced false negatives even further. from the original 45 FN to 6 FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b18ce0d-67c5-457c-9ff7-b5e9b35a0cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 1275\n",
      "False Negatives: 6\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "catboost = CatBoostClassifier(random_state=42, iterations=1000, verbose=0)\n",
    "catboost.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "y_pred = catboost.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f04a6-6399-4072-af0a-d37ebbca244e",
   "metadata": {},
   "source": [
    "## Xgboost does better but it sacrifices false positives too much "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8d64a603-1365-455f-aa2d-dec76b53756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 2289\n",
      "False Negatives: 5\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train XGBoost classifier with regularization\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42, n_estimators=200, verbosity=0,\n",
    "                                   reg_lambda=.5)  # Adjust regularization strength as needed\n",
    "\n",
    "xgb_classifier.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "y_pred = xgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38227502-0c12-4fe9-b11a-faa7833e77c7",
   "metadata": {},
   "source": [
    "## Randomforest does just as well as catboost. Better than Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c233cc69-6f73-472d-8caa-d39dfa7742a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 1394\n",
      "False Negatives: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 200, 300, 400, 500]}\n",
    "\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "## Confusion code\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a74d0b-56fe-4802-a77f-b317e275cfbf",
   "metadata": {},
   "source": [
    "## Below I try SVM and knn with different parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c085cd2b-4e7d-4d6b-b11a-584310f03fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier:\n",
      "False Positives: 1367\n",
      "False Negatives: 15\n",
      "SVM Classifier:\n",
      "False Positives: 1907\n",
      "False Negatives: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Apply Random Under Sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [2, 3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1,.5, 1, 2, 4],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for KNN\n",
    "grid_search_knn = GridSearchCV(knn_classifier, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Initialize GridSearchCV for SVM\n",
    "grid_search_svm = GridSearchCV(svm_classifier, param_grid_svm, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV for KNN\n",
    "grid_search_knn.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "# Fit GridSearchCV for SVM\n",
    "grid_search_svm.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "# Get best parameters and best estimators for both classifiers\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best estimators\n",
    "y_pred_knn = best_knn.predict(X_test_scaled)\n",
    "y_pred_svm = best_svm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of KNN\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "tn_knn, fp_knn, fn_knn, tp_knn = cm_knn.ravel()\n",
    "\n",
    "print(\"KNN Classifier:\")\n",
    "print(f\"False Positives: {fp_knn}\")\n",
    "print(f\"False Negatives: {fn_knn}\")\n",
    "\n",
    "# Evaluate the performance of SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "tn_svm, fp_svm, fn_svm, tp_svm = cm_svm.ravel()\n",
    "\n",
    "print(\"SVM Classifier:\")\n",
    "print(f\"False Positives: {fp_svm}\")\n",
    "print(f\"False Negatives: {fn_svm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0dcdd-5d5b-4825-83b5-32c13f372dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ae7d9-5858-4dd2-bede-ed8518a7ae12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
