{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32bd37d-1efc-4020-890a-ab8b01ea1ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9777777777777777\n",
      "Accuracy: 0.9610027855153204\n",
      "Accuracy: 0.9610027855153204\n",
      "Accuracy: 0.9442896935933147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold  # Import KFold from model_selection\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Separate features and labels\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_digits_normalized = scaler.fit_transform(X_digits)\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use the same k-fold split for training and testing\n",
    "for train_index, test_index in k_fold.split(X_digits_normalized, y_digits):\n",
    "    \n",
    "    \n",
    "    train_features, test_features = X_digits_normalized[train_index], X_digits_normalized[test_index]\n",
    "    \n",
    "    train_labels, test_labels = y_digits[train_index], y_digits[test_index]\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    logreg = LogisticRegression(max_iter=600, random_state=42)\n",
    "    logreg.fit(train_features, train_labels)\n",
    "\n",
    "    # Predict on the testing features\n",
    "    predictions = logreg.predict(test_features)\n",
    "\n",
    "    # Evaluate the accuracy\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05dbd0cd-179e-4122-98e2-567bc8941f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracy: 0.9666, Precision: 0.9674, Recall: 0.9666, F1 Score: 0.9667\n",
      "Confusion Matrix:\n",
      "[[55  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 52  2  0  0  0  0  0  1  2]\n",
      " [ 0  0 52  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 54  0  1  0  0  2  0]\n",
      " [ 0  1  0  0 63  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 69  1  0  0  3]\n",
      " [ 0  0  0  0  0  1 56  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 61  0  1]\n",
      " [ 0  1  0  0  0  1  0  0 51  0]\n",
      " [ 0  0  0  0  0  1  0  0  2 66]]\n",
      "\n",
      "Fold Accuracy: 0.9616, Precision: 0.9641, Recall: 0.9616, F1 Score: 0.9622\n",
      "Confusion Matrix:\n",
      "[[54  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 61  0  0  0  0  0  0  2  0]\n",
      " [ 0  1 55  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 64  0  0  0  0  4  1]\n",
      " [ 0  0  0  0 52  0  0  1  1  0]\n",
      " [ 0  0  0  1  0 53  0  0  0  3]\n",
      " [ 0  3  0  0  0  0 72  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 61  0  0]\n",
      " [ 0  4  0  0  0  0  0  0 53  0]\n",
      " [ 0  1  0  0  0  0  0  0  1 51]]\n",
      "\n",
      "Fold Accuracy: 0.9583, Precision: 0.9587, Recall: 0.9583, F1 Score: 0.9581\n",
      "Confusion Matrix:\n",
      "[[68  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 57  0  1  0  0  1  0  1  2]\n",
      " [ 0  0 68  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 55  0  2  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  1  2]\n",
      " [ 0  0  0  0  0 52  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 47  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 55  1  0]\n",
      " [ 0  2  1  2  0  2  1  0 56  0]\n",
      " [ 0  1  0  0  0  1  0  0  0 56]]\n",
      "\n",
      "Average Accuracy: 0.9622\n",
      "Average Precision: 0.9634\n",
      "Average Recall: 0.9622\n",
      "Average F1 Score: 0.9623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Separate features and labels\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_digits_normalized = scaler.fit_transform(X_digits)\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "k_fold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use the same k-fold split for training and testing\n",
    "for train_index, test_index in k_fold.split(X_digits_normalized, y_digits):\n",
    "    train_features, test_features = X_digits_normalized[train_index], X_digits_normalized[test_index]\n",
    "    train_labels, test_labels = y_digits[train_index], y_digits[test_index]\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    logreg = LogisticRegression(max_iter=600, random_state=42)\n",
    "    logreg.fit(train_features, train_labels)\n",
    "\n",
    "    # Predict on the testing features\n",
    "    predictions = logreg.predict(test_features)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, average='weighted')\n",
    "    recall = recall_score(test_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "    confusion_mat = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(confusion_mat)\n",
    "\n",
    "    # Print the metrics for each fold\n",
    "    print(f'Fold Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{confusion_mat}\\n')\n",
    "\n",
    "# Average metrics across folds\n",
    "avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_recall = sum(recalls) / len(recalls)\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print average metrics\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1 Score: {avg_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0bc17aa-3e3c-4517-a8bb-59d164747024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9588\n",
      "Random Forest Accuracy: 0.9577\n",
      "SVM Accuracy: 0.9722\n",
      "k-NN Accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Separate features and labels\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_digits_normalized = scaler.fit_transform(X_digits)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits_normalized, y_digits, test_size=0.50, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=600, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions_logreg = logreg.predict(X_test)\n",
    "accuracy_logreg = accuracy_score(y_test, predictions_logreg)\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logreg:.4f}')\n",
    "\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "predictions_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, predictions_rf)\n",
    "print(f'Random Forest Accuracy: {accuracy_rf:.4f}')\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_classifier = SVC(random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "predictions_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
    "print(f'SVM Accuracy: {accuracy_svm:.4f}')\n",
    "\n",
    "# k-Nearest Neighbors (k-NN)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "predictions_knn = knn_classifier.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, predictions_knn)\n",
    "print(f'k-NN Accuracy: {accuracy_knn:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
